#!/bin/bash

SCRIPT_DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" &> /dev/null && pwd )"

#terraform init -reconfigure -backend-config="$SCRIPT_DIR/$PROJECT.tfbackend"
#terraform destroy -var-file "$SCRIPT_DIR/$service/$service.tfvars" -auto-approve
#terraform apply -var-file "$SCRIPT_DIR/$service/$service.tfvars" -auto-approve

. ~/.gcp

SCRIPT_DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" &> /dev/null && pwd )"
cd ../..
mvn clean package -Pdist -DskipTests
cd "$SCRIPT_DIR" || exit

if [ -z "$OWNER" ]
then
  OWNER=$USER
fi
echo "OWNER=$OWNER"

JOB=$(echo "${OWNER}-$(basename $SCRIPT_DIR)" | tr '[:upper:]' '[:lower:]' )
echo "JOB=$JOB"

echo "Deleting manually resources owned by $OWNER ..."
gsutil -m rm -r "gs://${PROJECT}-${OWNER}-terraform/$(basename $SCRIPT_DIR)"
bq rm -r -f -d ${PROJECT}:${OWNER}_dataset
gcloud beta logging sinks delete "${JOB}-logging-sink" --quiet

#for name in $(gcloud monitoring dashboards list --filter="displayName='$JOB - all jobs'" --format 'value(NAME)');
#  do gcloud monitoring dashboards delete --quiet $name;
#done
for name in $(gcloud monitoring dashboards list --filter="displayName='$JOB redesigned job id'" --format 'value(NAME)'); do gcloud monitoring dashboards delete --quiet $name; done
for name in $(gcloud monitoring dashboards list --filter="displayName='$JOB redesigned job name'" --format 'value(NAME)'); do gcloud monitoring dashboards delete --quiet $name; done
for name in $(gcloud alpha monitoring policies list --filter "display_name~'$JOB.*'" --format 'value(NAME)'); do gcloud alpha monitoring policies delete $name --quiet ; done
for name in $(gcloud logging metrics list --filter "name~'$JOB.*'" --format 'value(NAME)'); do gcloud logging metrics delete $name --quiet; done
for name in $(gcloud beta monitoring channels list --filter "labels.email_address='${EMAIL}'" --format 'value(NAME)'); do gcloud beta monitoring channels delete $name --quiet ; done
max_retry=20; counter=1; sleep_secs=5; until [ -z "$(gcloud dataflow jobs list --filter "NAME:${JOB}-${EXPIRATION_DATE} AND (STATE=Cancelling OR STATE=Running)" --format 'value(JOB_ID)' --region $REGION)" ] ; do sleep $sleep_secs; [[ counter -eq $max_retry ]] && echo "Failed" && break; echo "waiting $sleep_secs secs for job to stop: attempt $counter" ; ((counter++)); done
gsutil rm -r "gs://${BUCKET}"
gsutil -q stat "gs://${PROJECT}-$OWNER-terraform/**" || gsutil mb "gs://${PROJECT}-$OWNER-terraform"


#cd $SCRIPT_DIR/../..
### Create template from java ###
#mvn clean package -DskipTests -Pmake-dist -Pdataflow-runner
#java -cp target/my-apache-beam-dataflow-0.1-SNAPSHOT.jar com.bawi.beam.dataflow.MyBQReadWriteJob \
# ${JAVA_DATAFLOW_RUN_OPTS} \
# --runner=DataflowRunner \
# --stagingLocation=gs://${BUCKET}/staging \
# --templateLocation=gs://${BUCKET}/templates/${JOB}-template

### Execute from template ###
#gcloud dataflow jobs run ${JOB}-template-${EXPIRATION_DATE} \
#  ${GCLOUD_DATAFLOW_RUN_OPTS} \
#  --gcs-location gs://${BUCKET}/templates/${JOB}-template \
#  --parameters expirationDate=${EXPIRATION_DATE}

if [ -f "$GOOGLE_APPLICATION_CREDENTIALS__JSON_FILE" ]
then
  echo "Exporting GOOGLE_APPLICATION_CREDENTIALS=$GOOGLE_APPLICATION_CREDENTIALS__JSON_FILE"
  export GOOGLE_APPLICATION_CREDENTIALS=$GOOGLE_APPLICATION_CREDENTIALS__JSON_FILE
fi

#gcloud dataflow jobs run $OWNER-mybqreadwritejob-template-2021-03-03 \
#  ${GCLOUD_DATAFLOW_RUN_OPTS} \
#  --gcs-location gs://$PROJECT-$OWNER-mybqreadwritejob/templates/$OWNER-mybqreadwritejob-template \
#  --parameters expirationDate=2021-03-03